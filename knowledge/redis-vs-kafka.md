# Redis Streams vs Kafka – Selection Notes

## Criteria
- **システム規模**: 今回は "初回50件 + SSE 通知" 程度の軽量ファンアウト。Kafka のような大規模ログ基盤はコスト過大。
- **運用負荷**: Redis は単一バイナリで扱いやすく、既存インフラに統合しやすい。Kafka はブローカー/コントローラ構築や監視が必須で、PoC には重い。
- **レイテンシ**: Redis Streams はメモリベースで低レイテンシ。SSE と組み合わせてもサブ秒〜数秒で収まる。
- **保持/リプレイの要件**: 長期保持・リプレイは不要（MAXLEN トリムで十分）。Kafka のディスクベースログは過剰。
- **開発速度**: NestJS から `XADD`/`XREAD` だけで構築可。Kafka クライアントやスキーマ管理の学習コストを避けたい。
- **将来拡張性**: Transactional Outbox → ブローカーという構成を維持しておけば、将来 Kafka へ差し替えも容易。

## Decision
上記理由により PoC/学習目的のリアルタイムダッシュボードでは Redis Streams を採用。Kafka が必要になるのは、
- パーティションに分散した大量イベントを長期間保持したい
- 複数システムへ CDC/ストリーム処理を連携したい
- 消費者グループや exactly-once に近い制御が必須
と言った要件が出てきたとき。

## References
- `backend/src/services/outbox-worker.service.ts` – Outbox→Redis ブリッジ。
- `backend/src/controllers/sse.controller.ts` – Redis Streams→SSE ブリッジ。

---

以下は自分が直接指定した要件

# Transactional Outbox + Pub/Sub Pattern

- **書き込み/配信の分離**  
  DB (Aurora/PostgreSQL) は events/outbox を RLS 付きで保持し、通知処理を一切持たない。`OutboxWorkerService` が Kafka/Redis などのブローカーへ publish することで、チャットなどの高頻度配信に見られる “Transactional Outbox + Broker” パターンを踏襲している。
- **SSE ブロードキャスト**  
  ブラウザは `EventSource` で `/sse` に接続し、バックエンドは Redis Streams から1回読み取ってすべての SSE クライアントにブロードキャストする。「ロードバランサ＋Pub/Sub」構成でスケールさせる設計と同じアプローチ。
- **拡張性**  
  ブローカーを Kafka に置き換える、WebSocket ゲートウェイを追加するなどの拡張が容易。Transactional Outbox の段差を維持しているため、チャット面接で紹介されるような高スケール構成にも発展させやすい。


```md
# 結論：今回のダッシュボード配信は Redis Streams で十分。Kafka は（今は）過剰スペック

## ユースケース（前提）
- 初回ロード時に Aurora PostgreSQL から **最新50件**を取得して、フロントのテーブル（shadcn datatable）に表示する
- その後に発生したイベント（DBに新規書き込みされた行）を、SSE（またはWebSocket）で **順次追加配信**してテーブルに反映したい
- ユーザがページをリロードすれば、再びDBから **最新50件だけ再取得**すればよい（= 長期の取りこぼしリカバリをDBフェッチで許容）

---

## 推奨アーキテクチャ（最小で成立する形）
1. **GET /events?limit=50**  
   - Aurora PostgreSQL から最新50件を取得して表示（初回描画）
2. **/events/stream（SSE）** 接続  
   - 以降の増分イベントを受け取って、テーブルに追加
3. バックエンド側の配信経路（例）
   - DB書き込み（業務処理）  
   - （堅牢化するなら）Outbox に insert  
   - Publisher が **Redis Streams に XADD**  
   - SSE Gateway が **XREAD(GROUP) で購読して配信**

---

## なぜ今回のケースは Redis Streams で十分か
### 1) 要件が「短期の増分配信」で完結している
- リロードすれば DB から最新50件を再取得できるため、  
  **長期リテンション**や**過去ログの大規模リプレイ**が必須ではない
- Redis Streams は「短期リテンションの配信レーン」と相性が良い

### 2) “配信の正” はDB側に置ける
- イベントの正本は Aurora 側にある
- Redis Streams は **リアルタイム配信用の一時的なストリーム**として扱える  
  → Redis 側で多少の取りこぼしが起きても、ページリロード（最新50件再取得）でユーザー体験を回復できる

### 3) コンシューマがフロント配信中心で、用途が固定
- 今回の主用途は「ダッシュボードへ即時反映」
- まだ「分析」「監査」「ML」「複数チームが独立に購読」などの要求が薄い  
  → Kafka の強み（多コンシューマ・契約管理・長期保持）が活きにくい

### 4) 運用コストが低い
- Redis（ElastiCache等）は構成が軽く、立ち上げが速い
- Kafka（MSK等）は得られるメリットが大きい一方で、クラスタ運用・容量設計・監視が重くなりがち  
  → 現時点の要求に対してはコスト過多になりやすい

---

## Redis Streams 運用で押さえるべきポイント（最低限）
- **重複前提（at-least-once）**：`eventId` を持たせて UI 側で重複排除できるようにする
- **リテンション設計**：`XADD ... MAXLEN ~ N` でトリムし、メモリ上限と整合を取る
- **切断時のフォールバック**：
  - 可能なら `lastEventId` を保持して再接続時に続きから読む
  - 追えない場合は「最新50件再取得」で回復（今回の要件的に許容）

---

## Kafka が必要になってくる “撤退条件”（将来の示唆）
次の要件が出てきたら Kafka を検討する価値が高い：

- **長期リテンション**（数日〜数ヶ月）や、任意時点からの**大規模リプレイ**が必要
- コンシューマが増える（配信だけでなく、**分析・監査・アラート・バッチ**などが同時に走る）
- イベント量が増えて、Redis のメモリ/トリム設計が負担になってきた
- マルチリージョン/DR を強く求める
- イベントが複数チーム間の「契約」になり、**スキーマ互換性の強制**が必要（Schema Registry 等）

---

## まとめ
今回のダッシュボードは、
- 初回はDBから最新50件を取得
- 以降は短期の増分をPushで足す
- 取りこぼしてもリロードで回復できる

という性質が強いため、**Redis Streams + SSE（またはWS）で十分成立**する。  
Kafka は「長期保持」「多用途購読」「大規模リプレイ」などが必要になった段階で導入すればよく、現時点では **過剰スペック**になりやすい。
```
